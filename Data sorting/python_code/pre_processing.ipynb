{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2782f216-edd0-493f-b973-f373767b4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = 1000\n",
    "data_path = r'C:\\Users\\Jisub\\Desktop\\Saccadic\\left\\data'\n",
    "save_path = r'C:\\Users\\Jisub\\Desktop\\Saccadic\\python_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d885647-5a70-493a-bd51-701c91fab07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc4a21-c6bd-4b4d-9015-4c3c9cc2bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_processing(Ts, data_path, save_path):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Ts = Ts\n",
    "        self.path = data_path\n",
    "        self.save_path = save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d680e79-c6e7-4466-8c9a-63f58a62f4f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T04:07:41.799120Z",
     "iopub.status.busy": "2025-04-07T04:07:41.798120Z",
     "iopub.status.idle": "2025-04-07T04:07:41.843352Z",
     "shell.execute_reply": "2025-04-07T04:07:41.842360Z",
     "shell.execute_reply.started": "2025-04-07T04:07:41.799120Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_data(self, p_epoch_setting, save_output = True):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate setting for epoch data.\n",
    "\n",
    "    Parameters:\n",
    "    - epoch_setting: Time of interest(TOI). e.g. [-300, 300] means make epoch data -300ms to 300ms TOI\n",
    "\n",
    "    Returns:\n",
    "    - total_epoch: Epoch setting for each cell containing:\n",
    "        - [0]: epoch setting (trial, amplitude > 7 degree, start time point, 1 is exist, 0 is nan, velopcity duration)\n",
    "        - [1]: epoch period (by Saccade)\n",
    "        - [2]: number of total data\n",
    "        - [3]: number of rejected data\n",
    "        - [4]: file list\n",
    "        - [5]: epoch period by stimulation (by TargetX and Y)\n",
    "    \"\"\"\n",
    "\n",
    "    # Set type\n",
    "    reject_trials = True  # True is reject minus trial else keep it original\n",
    "    \n",
    "    # Set epoch period\n",
    "    # Ts = 1000  # Sampling rate\n",
    "    Ts = self.Ts  # Sampling rate, ms\n",
    "    path = self.data_path\n",
    "    path2 = self.save_path\n",
    "    epoch_setting = np.array(p_epoch_setting) / 1000  # in seconds\n",
    "    eset = np.abs(np.round(epoch_setting * Ts)).astype(int)\n",
    "    \n",
    "    # Load data list\n",
    "    file_list = sorted(os.listdir(path))\n",
    "    del file_list[5]  # Remove 6th file, because this data seems odd!\n",
    "\n",
    "    # Preprocess data\n",
    "    total_epoch = []\n",
    "    \n",
    "    for fname in file_list:\n",
    "        data = sio.loadmat(os.path.join(path, fname), squeeze_me=True)\n",
    "        \n",
    "        Saccade = data['Saccade']\n",
    "        T0 = data['T1']\n",
    "        T1 = T0.toarray()\n",
    "        TargetX = data['TargetX']\n",
    "        TargetY = data['TargetY']\n",
    "        \n",
    "        s_amp = [s['amplitude'] for s in Saccade]\n",
    "        s_start = [s['start'] for s in Saccade]\n",
    "        s_dur = [s['duration'] for s in Saccade]\n",
    "        Time = T1.shape[1]\n",
    "    \n",
    "        # Find epoch time point by stimulus\n",
    "        sti_epoch = []\n",
    "        for x, y in zip(TargetX, TargetY):\n",
    "            temp = np.abs(x) + np.abs(y)\n",
    "            idx = np.argmax(temp > 1)\n",
    "            sti_epoch.append(idx)\n",
    "        \n",
    "        # Find epoch time point by saccade    \n",
    "        final_epoch = []\n",
    "        for t_num in range(len(s_amp)):\n",
    "            s_ampI = np.array(s_amp[t_num])\n",
    "            temp_amp = np.zeros(np.size(s_ampI), dtype=bool)\n",
    "            star_idx=s_start[t_num]<500; # before onset\n",
    "            s_ampI[star_idx]=0;\n",
    "    \n",
    "            if np.max(s_ampI)>7:\n",
    "                I = np.argmax(s_ampI)\n",
    "                temp_amp[I] = True\n",
    "    \n",
    "            if sum(temp_amp)==0:\n",
    "                c_label=0;\n",
    "            else:\n",
    "                c_label=1;\n",
    "    \n",
    "            if len(temp_amp) < 2:\n",
    "                if temp_amp == True:\n",
    "                    temp_start = s_start[t_num]\n",
    "                    temp_dur = s_dur[t_num]\n",
    "                elif temp_amp == False:\n",
    "                    temp_start = np.array([])\n",
    "                    temp_dur = np.array([])\n",
    "            else:\n",
    "                temp_start = s_start[t_num][temp_amp]\n",
    "                temp_dur = s_dur[t_num][temp_amp]\n",
    "    \n",
    "            final_epoch.append([t_num, temp_amp, temp_start, c_label, temp_dur])\n",
    "        \n",
    "        final_epochtime = []\n",
    "        for t_num in range(len(final_epoch)):\n",
    "    \n",
    "            temp_epoch = final_epoch[t_num]\n",
    "            stif_epoch = sti_epoch[t_num]        \n",
    "            if temp_epoch[3] == 0:\n",
    "                continue\n",
    "    \n",
    "            temp_times = temp_epoch[2]\n",
    "            temp_dur = temp_epoch[4]        \n",
    "    \n",
    "            final_ep=[]\n",
    "            final_ep2=np.array([stif_epoch-eset[0], stif_epoch+eset[1]])\n",
    "            if np.size(temp_times) < 2:\n",
    "                temp_priod=[temp_times-eset[0], temp_times+eset[1], temp_epoch[0], temp_dur]\n",
    "                final_ep.append(temp_priod)\n",
    "            else:\n",
    "                for len_epo in range(len(temp_times)):\n",
    "                    temp_priod=[temp_times[len_epo]-eset[0], temp_times[len_epo]+eset[1], temp_epoch[0], temp_dur]\n",
    "                    final_ep.append(temp_priod)\n",
    "    \n",
    "            final_epochtime.append(np.append(final_ep[0], final_ep2))\n",
    "    \n",
    "        final_epochtime=np.array(final_epochtime, dtype=object).astype(int)\n",
    "        \n",
    "    \n",
    "        if reject_trials:\n",
    "            valid = (final_epochtime[:,0] > 0) & (final_epochtime[:,1] <= Time)\n",
    "            final_epochtime2 = final_epochtime[valid]\n",
    "        else:\n",
    "            final_epochtime2 = final_epochtime\n",
    "    \n",
    "        total_epoch.append([\n",
    "            final_epoch,\n",
    "            final_epochtime2,\n",
    "            len(final_epochtime2),\n",
    "            len(final_epochtime) - len(final_epochtime2),\n",
    "            fname,\n",
    "            sti_epoch\n",
    "        ])\n",
    "        \n",
    "    total_epoch=np.array(total_epoch,dtype=object)\n",
    "    \n",
    "    return total_epoch\n",
    " \n",
    "    # Save the result\n",
    "    if save_output == True:\n",
    "        os.chdir(path2)\n",
    "        np.save('epoch_setting.npy',total_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465cccb6-f1e6-4089-a3de-93c41d63c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(self, save_output = True):\n",
    "\n",
    "    \"\"\"\n",
    "    Generate epoch data by epoch_setting\n",
    "\n",
    "    Parameters:\n",
    "    - need epoch_setting.npy\n",
    "\n",
    "    Returns:\n",
    "    - total_epoch: Epoch setting for each cell containing:\n",
    "        - [0]: TargetX epoched data\n",
    "        - [1]: TargetY epoched data\n",
    "        - [2]: velocity epoched data\n",
    "        - [3]: T1 epoched data\n",
    "        - [4]: velopcity duration\n",
    "        - [5]: T1 epoched data(by stimulus)\n",
    "    \"\"\"\n",
    "    \n",
    "    path = self.data_path\n",
    "    path2 = self.save_path\n",
    "    \n",
    "    # Load epoch setting\n",
    "    total_epoch=np.load('epoch_setting.npy', allow_pickle=True)\n",
    "    \n",
    "    # Load data list\n",
    "    os.chdir(path)\n",
    "    \n",
    "    # Preprocess data\n",
    "    total_epodata=[]\n",
    "    for a in range(len(total_epoch)):\n",
    "    \n",
    "        data = sio.loadmat(total_epoch[a,4], squeeze_me=True)\n",
    "        temp_epoch=total_epoch[a,1]\n",
    "        T0 = data['T1']\n",
    "        T2 = T0.toarray()\n",
    "        TargetX = data['TargetX']\n",
    "        TargetY = data['TargetY']\n",
    "        VelV = data['VelV']\n",
    "    \n",
    "        # Target stimulation and spike data\n",
    "        total_data1=[];\n",
    "        total_data2=[];\n",
    "        total_data3=[];\n",
    "        total_data4=[];\n",
    "        total_data5=[];\n",
    "        total_data6=[];\n",
    "        for epo_num in range(np.size(temp_epoch,0)):\n",
    "            \n",
    "            tval=temp_epoch[epo_num,:]\n",
    "            \n",
    "            # target stimulation\n",
    "            xx=TargetX[tval[2],:]\n",
    "            xx2=xx[tval[0]:tval[1]]\n",
    "            yy=TargetY[tval[2],:]\n",
    "            yy2=yy[tval[0]:tval[1]]\n",
    "            \n",
    "            # velocity data\n",
    "            VV=VelV[tval[2],:]\n",
    "            VV2=VV[tval[0]:tval[1]]\n",
    "            \n",
    "            # spike data\n",
    "            TT=T2[tval[2],:]\n",
    "            TT2=TT[tval[0]:tval[1]]\n",
    "    \n",
    "            # spike data epoching by stimulus\n",
    "            TT3=TT[tval[4]:tval[5]]\n",
    "            \n",
    "            total_data1.append(xx2) # TargetX epoched data\n",
    "            total_data2.append(yy2) # TargetY epoched data\n",
    "            total_data3.append(VV2) # velocity epoched data\n",
    "            total_data4.append(TT2) # T1 epoched data\n",
    "            total_data5.append(tval[3]) # velopcity duration\n",
    "            total_data6.append(TT3) # T1 epoched data(by stimulus)\n",
    "            \n",
    "        total_data1=np.array(total_data1)\n",
    "        total_data2=np.array(total_data2)\n",
    "        total_data3=np.array(total_data3)\n",
    "        total_data4=np.array(total_data4)\n",
    "        total_data5=np.array(total_data5)\n",
    "        total_data6=np.array(total_data6)\n",
    "            \n",
    "        total_data=[total_data1,total_data2,total_data3, total_data4, total_data5, total_data6]\n",
    "        total_epodata.append([total_data, total_epoch[a,4]])\n",
    "    \n",
    "    total_epodata=np.array(total_epodata,dtype=object)\n",
    "\n",
    "    # Save the result\n",
    "    os.chdir(path2)\n",
    "    np.save('epoched_data.npy',total_epodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95150626-1eb3-47b8-a25a-78b0e4ea4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasorting_orientation(type):\n",
    "    \"\"\"\n",
    "    Sort data by 8 orientation\n",
    "\n",
    "    Parameters:\n",
    "    - type: type = 1 is epoched by saccade, 2 is epoched by stimulus\n",
    "    - need epoched_data.npy\n",
    "    - need ori_templet.npy\n",
    "\n",
    "    Returns:\n",
    "    - final_cat\n",
    "    - data_cat\n",
    "    - val_cat\n",
    "    - dur_cat\n",
    "    - rejectedXY_cat\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    total_epodata=np.load('epoched_data.npy', allow_pickle=True)\n",
    "    ori_templet=np.load('ori_templet.npy', allow_pickle=True)\n",
    "    \n",
    "    # Preprocess data\n",
    "    # type=1 # type=1 is epoched by saccade, 2 is epoched by stimulus\n",
    "\n",
    "    final_cat=[]\n",
    "    data_cat=[]\n",
    "    val_cat=[]\n",
    "    dur_cat=[]\n",
    "    rejectedXY_cat=[]\n",
    "    for c_num in range(len(total_epodata)):\n",
    "    \n",
    "        temp_s=total_epodata[c_num,0]\n",
    "        X=temp_s[0]; Y=temp_s[1]; TargetXY=[X[:,500],Y[:,500]]; tt=np.shape(X)\n",
    "        \n",
    "        cat_ori=np.zeros(tt[0])\n",
    "        for a in range(len(ori_templet)):\n",
    "    \n",
    "            temp_ot=ori_templet[a,:]\n",
    "            temp_ot=np.tile(temp_ot,np.size(TargetXY,axis=1))\n",
    "            temp_ot=temp_ot.reshape(np.shape(TargetXY)[1],np.shape(TargetXY)[0])\n",
    "            idx=np.round(TargetXY)==np.round(temp_ot.T)\n",
    "            idx2=np.sum(idx, axis=0)\n",
    "            idx3=idx2==2\n",
    "            cat_ori[idx3]=a+1\n",
    "    \n",
    "        final_cat.append(cat_ori)\n",
    "    \n",
    "        # sorting data as orientation\n",
    "        \n",
    "        if type==1:\n",
    "            TT=temp_s[3]\n",
    "        elif type==2:\n",
    "            TT=temp_s[5]\n",
    "    \n",
    "        VV=temp_s[2]\n",
    "        DD=temp_s[4]\n",
    "    \n",
    "        idx_all = [cat_ori == i for i in range(9)]\n",
    "    \n",
    "        # spike data sorting\n",
    "        data_catt=[TT[idx_all[1],:],\n",
    "                  TT[idx_all[2],:],\n",
    "                  TT[idx_all[3],:],\n",
    "                  TT[idx_all[4],:],\n",
    "                  TT[idx_all[5],:],\n",
    "                  TT[idx_all[6],:],\n",
    "                  TT[idx_all[7],:],\n",
    "                  TT[idx_all[8],:],\n",
    "                  TT[idx_all[0],:]\n",
    "                 ]\n",
    "        data_cat.append(np.array(data_catt))\n",
    "    \n",
    "        # velocity data sorting\n",
    "        val_catt=[VV[idx_all[1],:],\n",
    "                 VV[idx_all[2],:],\n",
    "                 VV[idx_all[3],:],\n",
    "                 VV[idx_all[4],:],\n",
    "                 VV[idx_all[5],:],\n",
    "                 VV[idx_all[6],:],\n",
    "                 VV[idx_all[7],:],\n",
    "                 VV[idx_all[8],:],\n",
    "                 VV[idx_all[0],:]\n",
    "                ]\n",
    "        val_cat.append(np.array(val_catt))\n",
    "    \n",
    "        # duration data sorting\n",
    "        dur_catt=[DD[idx_all[1]],\n",
    "                 DD[idx_all[2]],\n",
    "                 DD[idx_all[3]],\n",
    "                 DD[idx_all[4]],\n",
    "                 DD[idx_all[5]],\n",
    "                 DD[idx_all[6]],\n",
    "                 DD[idx_all[7]],\n",
    "                 DD[idx_all[8]],\n",
    "                 DD[idx_all[0]]\n",
    "                ]\n",
    "        dur_cat.append(np.array(dur_catt))    \n",
    "    \n",
    "        # X, Y data for rejected data\n",
    "        rejectedXY_catt=np.array([X[idx_all[0],:],Y[idx_all[0],:]])\n",
    "        rejectedXY_cat.append(rejectedXY_catt)\n",
    "    \n",
    "        print(np.shape(VV)[0], np.shape(DD))\n",
    "    \n",
    "    # accumulate total cell of each orientation\n",
    "    datacat_total=[]\n",
    "    valcat_total=[]\n",
    "    datacat_num=[]\n",
    "    for a in range(8):\n",
    "    \n",
    "        temp=[]\n",
    "        temp2=[]\n",
    "        temp_num=[]\n",
    "        for c_num in range(len(data_cat)):\n",
    "    \n",
    "            pre_temp=data_cat[c_num][a]\n",
    "            pre_temp2=val_cat[c_num][a]\n",
    "    \n",
    "            temp.append(pre_temp)\n",
    "            temp2.append(pre_temp2)\n",
    "            temp_num.append(np.shape(pre_temp)[0])\n",
    "    \n",
    "        datacat_total.append(temp)\n",
    "        valcat_total.append(temp2)\n",
    "        datacat_num.append(temp_num)\n",
    "    \n",
    "    return final_cat, data_cat, val_cat, dur_cat, rejectedXY_cat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
